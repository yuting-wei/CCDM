# CCDM
A cross-temporal contrastive disentangled model for ancient Chinese understanding.

## Model Download
The pre-trained language model is available for download on [Google Drive](https://drive.google.com/file/d/1udzlxseTW2DH8M6Ydl4c68oS4LxBJSsk/view?usp=sharing).

## Evaluation
The evaluation codes can be found in the [ACU_tasks](ACU_tasks) directory. Please refer to the links in our paper for the relevant datasets.

## Citation

Please cite our paper if you use our model.
```
@article{WEI2024106559,
        title = {A cross-temporal contrastive disentangled model for ancient Chinese understanding},
        journal = {Neural Networks},
        pages = {106559},
        year = {2024},
        issn = {0893-6080},
        doi = {https://doi.org/10.1016/j.neunet.2024.106559},
        url = {https://www.sciencedirect.com/science/article/pii/S0893608024004830}
}
```
